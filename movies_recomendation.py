# -*- coding: utf-8 -*-
"""Movies Recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12b4q387FcdE2a9gJZfMLd-ocqc8aIONC
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import ast
from sklearn.feature_extraction.text import CountVectorizer
import nltk
from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize
from sklearn.metrics.pairwise import cosine_similarity

"""Loading Dataset through google drive

"""

Dataset1 = '/content/drive/MyDrive/DataSet_ML/Movie Recomendation/tmdb_5000_credits.csv'
Dataset2 = '/content/drive/MyDrive/DataSet_ML/Movie Recomendation/tmdb_5000_movies.csv'

df_1 = pd.read_csv(Dataset1)
df_2 = pd.read_csv(Dataset2)

"""Features of dataset 1"""

df_1.columns

"""Features of dataset 2"""

df_2.columns

df_1.head()

df_2.head()

"""Created a new dataframe called 'new_df', which has important features related to our analysis.
1. Movie_id = Important to track moves
2. title = important as name of movie
3. cast = Cast is very important for some people to select movies
4. Crew = Here director name is very prominent feature
5. genres = importat as which type of movies it is
6. keywords = used for suggestion and finding of movie
7. overview = to know the summery of movies
8. Production_companies = imporant for some viewers
"""

new_df = pd.concat([df_1[['movie_id', 'title', 'cast', 'crew']], df_2[['genres', 'keywords', 'overview', 'production_companies']]], axis = 1)

new_df.shape

"""Checking if there any null value."""

new_df.isnull().sum()

"""Here only three null values is found in overview so dropping that will not affect much as we have 4803 X 3 dataset"""

#dropping the null values
new_df.dropna(inplace=True)

# Checked is there any duplicate values
new_df.duplicated().sum()

new_df

new_df.iloc[1].genres

"""We have featues in string list so converting it into in list datatype"""

# function to convert string into list
def list_convert(string_list):
  my_list = ast.literal_eval(string_list)
  new_list = []
  for kewords in my_list:
    new_list.append(kewords['name'])
  return new_list

"""Converting all features into list using list_convert function"""

new_df['genres'] = new_df['genres'].apply(list_convert)

new_df.iloc[0].cast

new_df['cast'] = new_df['cast'].apply(list_convert)

new_df.iloc[0].keywords

new_df['keywords'] = new_df['keywords'].apply(list_convert)

new_df.iloc[0].production_companies

new_df['production_companies'] = new_df['production_companies'].apply(list_convert)

new_df.iloc[0].crew

# function to find the director form crew feature
def list_convert_director(string_list):
  my_list = ast.literal_eval(string_list)
  new_list = []
  for kewords in my_list:
    if kewords['job'] == 'Director':
      new_list.append(kewords['name'])
      break
  return new_list

new_df['crew'] = new_df['crew'].apply(list_convert_director)

new_df.iloc[0].overview

def list_make(string):
  new_list = [string]
  return new_list

new_df['overview'] = new_df['overview'].apply(list_make)

"""Removing the space between the names and words"""

new_df['cast'] = new_df['cast'].apply(lambda x: [i.replace(" ", "") for i in x])
new_df['crew'] = new_df['crew'].apply(lambda x: [i.replace(" ", "") for i in x])
new_df['genres'] = new_df['genres'].apply(lambda x: [i.replace(" ", "") for i in x])
new_df['keywords'] = new_df['keywords'].apply(lambda x: [i.replace(" ", "") for i in x])
# new_df['overview'] = new_df['overview'].apply(lambda x: [i.replace(" ", "") for i in x])
new_df['production_companies'] = new_df['production_companies'].apply(lambda x: [i.replace(" ", "") for i in x])

new_df['tags'] = new_df['cast'] + new_df['crew'] + new_df['genres'] + new_df['keywords'] + new_df['overview'] + new_df['production_companies']

new_df

"""Final_df is made by using three features movie_id, title and tags, which is made by concatination of list of others all featuers"""

final_df = new_df[['movie_id', 'title', 'tags']]
final_df

final_df['tags'] = final_df['tags'].apply(lambda x: " ".join(x))
final_df

"""**Stemming**

Before stemming
"""

final_df['tags'][0]

nltk.download('punkt')

ps = PorterStemmer()

def stemmer_sentenses(string):
  words_in_sentence = word_tokenize(string)
  # print(words_in_sentence)
  steemer_words = []
  for w in words_in_sentence:
      steemer_words.append(ps.stem(w))
  return " ".join(steemer_words)

final_df['tags'] = final_df['tags'].apply(stemmer_sentenses)

"""After Stemming"""

final_df['tags'][0]

"""**Performing text vectorization**"""

cv = CountVectorizer(max_features=5000, stop_words='english')

final_df_vectores = cv.fit_transform(final_df['tags']).toarray()

final_df_vectores

for i in cv.get_feature_names_out():
  print(i)

cv.get_stop_words()

"""Calculating Cosine similarity between all vectors"""

cosine_similirity = cosine_similarity(final_df_vectores)

cosine_similirity

sorted(list(enumerate(cosine_similirity[4])), reverse=True, key = lambda x:x[1])

"""Fetching the top 10 movies on basis of cosine similarity"""

def movie_recomened(movie_title):
  if movie_title in final_df['title'].values:
    suggested_movies = []
    movie_index = final_df[final_df['title'] == movie_title].index[0]
    distance = cosine_similirity[movie_index]
    movies_list = sorted(list(enumerate(distance)), reverse=True, key = lambda x:x[1])[1:11]
    for movie_names in movies_list:
      suggested_movies.append(new_df.iloc[movie_names[0]].title)
    return suggested_movies
  else:
    print("No such movie found")

"""Function to print all 10 suggested movies"""

def find_movies():
  movies = input("Enter the name of Movie: ")
  print("Top 10 Suggested movies are: \n")
  if movie_recomened(movies) is not None:
    for i, j in enumerate(movie_recomened(movies)):
      print(i+1, j)

"""Run the cell to find movies"""

find_movies()

"""Run the cell to find movies"""

find_movies()

"""**List of all Movies**"""

final_df['title'].tolist()

